import argparse
import contextlib
import html as html_module
import json
import locale
import os
import re
from datetime import datetime, timezone
from typing import Any

LAST_ENTRY_TIME_FILE = "last_entry_time.txt"

# TRANSLATIONSã«å«ã¾ã‚Œã‚‹è¨€èªžåã‹ã‚‰ISO 639-1ã‚³ãƒ¼ãƒ‰ã¸ã®ãƒžãƒƒãƒ”ãƒ³ã‚°è¾žæ›¸
LANG_MAP = {
    "Arabic": "ar",
    "Bengali": "bn",
    "German": "de",
    "English": "en",
    "Spanish": "es",
    "Persian": "fa",
    "French": "fr",
    "Hindi": "hi",
    "Indonesian": "id",
    "Japanese": "ja",
    "Javanese": "jv",
    "Korean": "ko",
    "Marathi": "mr",
    "Malay": "ms",
    "Punjabi": "pa",
    "Portuguese": "pt",
    "Russian": "ru",
    "Swahili": "sw",
    "Tamil": "ta",
    "Telugu": "te",
    "Thai": "th",
    "Turkish": "tr",
    "Ukrainian": "uk",
    "Urdu": "ur",
    "Vietnamese": "vi",
    "Chinese_China": "zh_CN",
    "Chinese_Taiwan": "zh_TW",
}

TRANSLATIONS = {
    "ar": {
        "error_lang_detection": "Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§ÙƒØªØ´Ø§Ù Ù„ØºØ© Ø§Ù„Ù†Ø¸Ø§Ù…: {}",
        "file_not_found": "Ø®Ø·Ø£: Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {}",
        "json_decode_error": "Ø®Ø·Ø£ ÙÙŠ ÙÙƒ ØªØ±Ù…ÙŠØ² JSON: {}",
        "start_processing": "ðŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ {}...",
        "extracted_entries": "ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {0} Ù…Ø¯Ø®Ù„Ø§ØªØŒ Ù…Ù†Ù‡Ø§ {1} Ù‡ÙŠ Ø³Ø¬Ù„ Gemini.",
        "converting_markdown": "Ø¬Ø§Ø±Ù Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Markdown...",
        "appended_to_file": "ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù…Ù„Ù: {}",
        "written_to_file": "ØªÙ… ÙƒØªØ§Ø¨Ø© Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù…Ù„Ù: {}",
        "processing_complete": "âœ… Ø§ÙƒØªÙ…Ù„: ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø³Ø¬Ù„ Ù…Ù† {0} Ø¥Ù„Ù‰ {1} ÙÙŠ Ø¥Ø¬Ù…Ø§Ù„ÙŠ {2} Ù…Ù„ÙØ§Øª.",
        "error_occurred": "Ø­Ø¯Ø« Ø®Ø·Ø£: {}",
    },
    "bn": {
        "error_lang_detection": "à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦® à¦­à¦¾à¦·à¦¾ à¦¸à¦¨à¦¾à¦•à§à¦¤à¦•à¦°à¦£à§‡ à¦¤à§à¦°à§à¦Ÿà¦¿: {}",
        "file_not_found": "à¦¤à§à¦°à§à¦Ÿà¦¿: à¦«à¦¾à¦‡à¦² à¦ªà¦¾à¦“à¦¯à¦¼à¦¾ à¦¯à¦¾à¦¯à¦¼à¦¨à¦¿: {}",
        "json_decode_error": "JSON à¦¡à¦¿à¦•à§‹à¦¡ à¦¤à§à¦°à§à¦Ÿà¦¿: {}",
        "start_processing": "ðŸš€ à¦ªà§à¦°à¦•à§à¦°à¦¿à¦¯à¦¼à¦¾à¦•à¦°à¦£ à¦¶à§à¦°à§ à¦¹à¦šà§à¦›à§‡: {} à¦²à§‹à¦¡ à¦¹à¦šà§à¦›à§‡...",
        "extracted_entries": "{0} à¦à¦¨à§à¦Ÿà§à¦°à¦¿ à¦¬à§‡à¦° à¦•à¦°à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡, à¦¯à¦¾à¦° à¦®à¦§à§à¦¯à§‡ {1} à¦Ÿà¦¿ Gemini à¦‡à¦¤à¦¿à¦¹à¦¾à¦¸à¥¤",
        "converting_markdown": "Markdown à¦ à¦°à§‚à¦ªà¦¾à¦¨à§à¦¤à¦° à¦•à¦°à¦¾ à¦¹à¦šà§à¦›à§‡...",
        "appended_to_file": "à¦šà§à¦¯à¦¾à¦Ÿ à¦‡à¦¤à¦¿à¦¹à¦¾à¦¸ à¦«à¦¾à¦‡à¦²à§‡ à¦¯à§‹à¦— à¦•à¦°à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡: {}",
        "written_to_file": "à¦šà§à¦¯à¦¾à¦Ÿ à¦‡à¦¤à¦¿à¦¹à¦¾à¦¸ à¦«à¦¾à¦‡à¦²à§‡ à¦²à§‡à¦–à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡: {}",
        "processing_complete": "âœ… à¦¸à¦®à§à¦ªà¦¨à§à¦¨: {0} à¦¥à§‡à¦•à§‡ {1} à¦ªà¦°à§à¦¯à¦¨à§à¦¤ à¦‡à¦¤à¦¿à¦¹à¦¾à¦¸ à¦®à§‹à¦Ÿ {2} à¦«à¦¾à¦‡à¦²à§‡ à¦¸à¦‚à¦°à¦•à§à¦·à¦£ à¦•à¦°à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡à¥¤",
        "error_occurred": "à¦à¦•à¦Ÿà¦¿ à¦¤à§à¦°à§à¦Ÿà¦¿ à¦˜à¦Ÿà§‡à¦›à§‡: {}",
    },
    "de": {
        "error_lang_detection": "Fehler bei der Erkennung der Systemsprache: {}",
        "file_not_found": "Fehler: Datei nicht gefunden: {}",
        "json_decode_error": "JSON-Decodierungsfehler: {}",
        "start_processing": "ðŸš€ Verarbeitung gestartet: Lade {}...",
        "extracted_entries": "{0} EintrÃ¤ge extrahiert, davon sind {1} Gemini-Verlauf.",
        "converting_markdown": "Konvertiere zu Markdown...",
        "appended_to_file": "ChatverlÃ¤ufe an Datei angehÃ¤ngt: {}",
        "written_to_file": "ChatverlÃ¤ufe in Datei geschrieben: {}",
        "processing_complete": "âœ… Abgeschlossen: Verlauf von {0} bis {1} in insgesamt {2} Dateien gespeichert.",
        "error_occurred": "Ein Fehler ist aufgetreten: {}",
    },
    "en": {
        "error_lang_detection": "Error while detecting system language: {}",
        "file_not_found": "Error: File not found: {}",
        "json_decode_error": "JSON decode error: {}",
        "start_processing": "ðŸš€ Starting processing: Loading {}...",
        "extracted_entries": "Extracted {0} entries, of which {1} are Gemini history.",
        "converting_markdown": "Converting to Markdown...",
        "appended_to_file": "Chat histories appended to file: {}",
        "written_to_file": "Chat histories written to file: {}",
        "processing_complete": "âœ… Completed: Saved history after {0} to {1} into a total of {2} files.",
        "error_occurred": "An error occurred: {}",
    },
    "es": {
        "error_lang_detection": "Error al detectar el idioma del sistema: {}",
        "file_not_found": "Error: Archivo no encontrado: {}",
        "json_decode_error": "Error al decodificar JSON: {}",
        "start_processing": "ðŸš€ Iniciando procesamiento: Cargando {}...",
        "extracted_entries": "Se extrajeron {0} entradas, de las cuales {1} son historial de Gemini.",
        "converting_markdown": "Convirtiendo a Markdown...",
        "appended_to_file": "Historiales de chat agregados al archivo: {}",
        "written_to_file": "Historiales de chat escritos en el archivo: {}",
        "processing_complete": "âœ… Completado: Historial guardado desde {0} hasta {1} en un total de {2} archivos.",
        "error_occurred": "OcurriÃ³ un error: {}",
    },
    "fa": {
        "error_lang_detection": "Ø®Ø·Ø§ Ø¯Ø± Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø²Ø¨Ø§Ù† Ø³ÛŒØ³ØªÙ…: {}",
        "file_not_found": "Ø®Ø·Ø§: ÙØ§ÛŒÙ„ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯: {}",
        "json_decode_error": "Ø®Ø·Ø§ÛŒ Ø±Ù…Ø²Ú¯Ø´Ø§ÛŒÛŒ JSON: {}",
        "start_processing": "ðŸš€ Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´: Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ {}...",
        "extracted_entries": "{0} ÙˆØ±ÙˆØ¯ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯ Ú©Ù‡ {1} Ù…ÙˆØ±Ø¯ Ø§Ø² Ø¢Ù†â€ŒÙ‡Ø§ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Gemini Ø§Ø³Øª.",
        "converting_markdown": "Ø¯Ø± Ø­Ø§Ù„ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Markdown...",
        "appended_to_file": "ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú†Øª Ø¨Ù‡ ÙØ§ÛŒÙ„ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯: {}",
        "written_to_file": "ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú†Øª Ø¯Ø± ÙØ§ÛŒÙ„ Ù†ÙˆØ´ØªÙ‡ Ø´Ø¯: {}",
        "processing_complete": "âœ… ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯: ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø§Ø² {0} ØªØ§ {1} Ø¯Ø± Ù…Ø¬Ù…ÙˆØ¹ Ø¯Ø± {2} ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.",
        "error_occurred": "ÛŒÚ© Ø®Ø·Ø§ Ø±Ø® Ø¯Ø§Ø¯: {}",
    },
    "fr": {
        "error_lang_detection": "Erreur lors de la dÃ©tection de la langue du systÃ¨me : {}",
        "file_not_found": "Erreur : Fichier non trouvÃ© : {}",
        "json_decode_error": "Erreur de dÃ©codage JSON : {}",
        "start_processing": "ðŸš€ DÃ©marrage du traitement : Chargement de {}...",
        "extracted_entries": "{0} entrÃ©es extraites, dont {1} sont l'historique Gemini.",
        "converting_markdown": "Conversion en Markdown...",
        "appended_to_file": "Historiques de chat ajoutÃ©s au fichier : {}",
        "written_to_file": "Historiques de chat Ã©crits dans le fichier : {}",
        "processing_complete": "âœ… TerminÃ© : Historique sauvegardÃ© de {0} Ã  {1} dans un total de {2} fichiers.",
        "error_occurred": "Une erreur est survenue : {}",
    },
    "hi": {
        "error_lang_detection": "à¤¤à¥à¤°à¥à¤Ÿà¤¿: à¤¸à¤¿à¤¸à¥à¤Ÿà¤® à¤­à¤¾à¤·à¤¾ à¤•à¤¾ à¤ªà¤¤à¤¾ à¤²à¤—à¤¾à¤¨à¥‡ à¤®à¥‡à¤‚ à¤¸à¤®à¤¸à¥à¤¯à¤¾: {}",
        "file_not_found": "à¤¤à¥à¤°à¥à¤Ÿà¤¿: à¤«à¤¼à¤¾à¤‡à¤² à¤¨à¤¹à¥€à¤‚ à¤®à¤¿à¤²à¥€: {}",
        "json_decode_error": "JSON à¤¡à¤¿à¤•à¥‹à¤¡ à¤¤à¥à¤°à¥à¤Ÿà¤¿: {}",
        "start_processing": "ðŸš€ à¤ªà¥à¤°à¤¸à¤‚à¤¸à¥à¤•à¤°à¤£ à¤¶à¥à¤°à¥‚ à¤¹à¥‹ à¤°à¤¹à¤¾ à¤¹à¥ˆ: {} à¤²à¥‹à¤¡ à¤¹à¥‹ à¤°à¤¹à¤¾ à¤¹à¥ˆ...",
        "extracted_entries": "Ditemukan {0} entri, di mana {1} adalah riwayat Gemini.",
        "converting_markdown": "Mengonversi ke Markdown...",
        "appended_to_file": "Riwayat obrolan ditambahkan ke file: {}",
        "written_to_file": "Riwayat obrolan ditulis ke file: {}",
        "processing_complete": "âœ… Selesai: Riwayat disimpan dari {0} hingga {1} dalam total {2} file.",
        "error_occurred": "Terjadi kesalahan: {}",
    },
    "id": {
        "error_lang_detection": "Error saat mendeteksi bahasa sistem: {}",
        "file_not_found": "Error: File tidak ditemukan: {}",
        "json_decode_error": "Error decode JSON: {}",
        "start_processing": "ðŸš€ Memulai pemrosesan: Memuat {}...",
        "extracted_entries": "Estratti {0} voci, di cui {1} sono cronologia di Gemini.",
        "converting_markdown": "Conversione in Markdown...",
        "appended_to_file": "Cronologia chat aggiunta al file: {}",
        "written_to_file": "Cronologia chat scritta nel file: {}",
        "processing_complete": "âœ… Completato: Cronologia salvata da {0} a {1} in un totale di {2} file.",
        "error_occurred": "Si Ã¨ verificato un errore: {}",
    },
    "ja": {
        "error_lang_detection": "ã‚·ã‚¹ãƒ†ãƒ è¨€èªžã®æ¤œå‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {}",
        "file_not_found": "ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {}",
        "json_decode_error": "JSONãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {}",
        "start_processing": "ðŸš€ å‡¦ç†é–‹å§‹: {} ã‚’èª­ã¿è¾¼ã¿ä¸­...",
        "extracted_entries": "{0} ä»¶æŠ½å‡ºã•ã‚Œã€ã†ã¡ Gemini ã®å±¥æ­´ã¯ {1} ä»¶ã‚ã‚Šã¾ã—ãŸã€‚",
        "converting_markdown": "Markdown ã«å¤‰æ›ä¸­...",
        "appended_to_file": "ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜ã—ã¾ã—ãŸ: {}",
        "written_to_file": "ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿ã¾ã—ãŸ: {}",
        "processing_complete": "âœ… å®Œäº†ã—ã¾ã—ãŸ: {0} ã‚ˆã‚Šå¾Œã® {1} ã¾ã§ã®å±¥æ­´ã‚’å»¶ã¹ {2} ãƒ•ã‚¡ã‚¤ãƒ«ã«åˆ†å‰²ä¿å­˜ã—ã¾ã—ãŸã€‚",
        "error_occurred": "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {}",
    },
    "jv": {
        "error_lang_detection": "Kesalahan saat mendeteksi bahasa sistem: {}",
        "file_not_found": "Kesalahan: Berkas tidak ditemukan: {}",
        "json_decode_error": "Kesalahan dekode JSON: {}",
        "start_processing": "ðŸš€ Memulai pemrosesan: Memuat {}...",
        "extracted_entries": "Ditemukan {0} entri, di mana {1} adalah riwayat Gemini.",
        "converting_markdown": "Mengonversi ke Markdown...",
        "appended_to_file": "Riwayat obrolan ditambahkan ke berkas: {}",
        "written_to_file": "Riwayat obrolan ditulis ke berkas: {}",
        "processing_complete": "âœ… Selesai: Riwayat disimpan dari {0} hingga {1} dalam total {2} berkas.",
        "error_occurred": "Terjadi kesalahan: {}",
    },
    "ko": {
        "error_lang_detection": "ì‹œìŠ¤í…œ ì–¸ì–´ ì„¤ì • ê°ì§€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {}",
        "file_not_found": "ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {}",
        "json_decode_error": "JSON ë””ì½”ë“œ ì˜¤ë¥˜: {}",
        "start_processing": "ðŸš€ ì²˜ë¦¬ ì‹œìž‘: {} ë¡œë“œ ì¤‘...",
        "extracted_entries": "{0}ê°œì˜ í•­ëª©ì´ ì¶”ì¶œë˜ì—ˆìœ¼ë©°, ê·¸ ì¤‘ {1}ê°œëŠ” Gemini ê¸°ë¡ìž…ë‹ˆë‹¤.",
        "converting_markdown": "Markdownìœ¼ë¡œ ë³€í™˜ ì¤‘...",
        "appended_to_file": "ì±„íŒ… ê¸°ë¡ì´ íŒŒì¼ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤: {}",
        "written_to_file": "ì±„íŒ… ê¸°ë¡ì´ íŒŒì¼ì— ìž‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {}",
        "processing_complete": "âœ… ì™„ë£Œ: {0}ë¶€í„° {1}ê¹Œì§€ì˜ ê¸°ë¡ì´ ì´ {2}ê°œì˜ íŒŒì¼ì— ì €ìž¥ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "error_occurred": "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {}",
    },
    "mr": {
        "error_lang_detection": "à¤¤à¥à¤°à¥à¤Ÿà¥€: à¤¸à¤¿à¤¸à¥à¤Ÿà¤® à¤­à¤¾à¤·à¤¾ à¤“à¤³à¤–à¤£à¥à¤¯à¤¾à¤¤ à¤¸à¤®à¤¸à¥à¤¯à¤¾: {}",
        "file_not_found": "à¤¤à¥à¤°à¥à¤Ÿà¥€: à¤«à¤¾à¤‡à¤² à¤¸à¤¾à¤ªà¤¡à¤²à¥€ à¤¨à¤¾à¤¹à¥€: {}",
        "json_decode_error": "JSON à¤¡à¤¿à¤•à¥‹à¤¡ à¤¤à¥à¤°à¥à¤Ÿà¥€: {}",
        "start_processing": "ðŸš€ à¤ªà¥à¤°à¤•à¥à¤°à¤¿à¤¯à¤¾ à¤¸à¥à¤°à¥‚ à¤¹à¥‹à¤£à¤¾à¤° à¤†à¤¹à¥‡: {} à¤²à¥‹à¤¡ à¤¹à¥‹à¤¤ à¤†à¤¹à¥‡...",
        "extracted_entries": "{0} à¤¨à¥‹à¤‚à¤¦à¥€ à¤•à¤¾à¤¢à¤²à¥à¤¯à¤¾, à¤œà¥à¤¯à¤¾à¤ªà¥ˆà¤•à¥€ {1} Gemini à¤‡à¤¤à¤¿à¤¹à¤¾à¤¸ à¤†à¤¹à¥‡.",
        "converting_markdown": "Markdown à¤®à¤§à¥à¤¯à¥‡ à¤°à¥‚à¤ªà¤¾à¤‚à¤¤à¤°à¤¿à¤¤ à¤•à¤°à¤¤ à¤†à¤¹à¥‡...",
        "appended_to_file": "à¤šà¥…à¤Ÿ à¤‡à¤¤à¤¿à¤¹à¤¾à¤¸ à¤«à¤¾à¤‡à¤²à¤®à¤§à¥à¤¯à¥‡ à¤œà¥‹à¤¡à¤²à¤¾ à¤—à¥‡à¤²à¤¾: {}",
        "written_to_file": "à¤šà¥…à¤Ÿ à¤‡à¤¤à¤¿à¤¹à¤¾à¤¸ à¤«à¤¾à¤‡à¤²à¤®à¤§à¥à¤¯à¥‡ à¤²à¤¿à¤¹à¤¿à¤²à¤¾ à¤—à¥‡à¤²à¤¾: {}",
        "processing_complete": "âœ… à¤ªà¥‚à¤°à¥à¤£ à¤à¤¾à¤²à¥‡: à¤‡à¤¤à¤¿à¤¹à¤¾à¤¸ {0} à¤ªà¤¾à¤¸à¥‚à¤¨ {1} à¤ªà¤°à¥à¤¯à¤‚à¤¤ à¤à¤•à¥‚à¤£ {2} à¤«à¤¾à¤‡à¤²à¤®à¤§à¥à¤¯à¥‡ à¤œà¤¤à¤¨ à¤•à¥‡à¤²à¤¾ à¤—à¥‡à¤²à¤¾.",
        "error_occurred": "à¤à¤• à¤¤à¥à¤°à¥à¤Ÿà¥€ à¤†à¤²à¥€ à¤†à¤¹à¥‡: {}",
    },
    "ms": {
        "error_lang_detection": "Ralat semasa mengesan bahasa sistem: {}",
        "file_not_found": "Ralat: Fail tidak dijumpai: {}",
        "json_decode_error": "Ralat nyahkod JSON: {}",
        "start_processing": "ðŸš€ Memulakan pemprosesan: Memuat {}...",
        "extracted_entries": "Diekstrak {0} entri, di mana {1} adalah sejarah Gemini.",
        "converting_markdown": "Menukar kepada Markdown...",
        "appended_to_file": "Sejarah sembang ditambah ke fail: {}",
        "written_to_file": "Sejarah sembang ditulis ke fail: {}",
        "processing_complete": "âœ… Selesai: Sejarah disimpan dari {0} hingga {1} dalam jumlah {2} fail.",
        "error_occurred": "Ralat telah berlaku: {}",
    },
    "pa": {
        "error_lang_detection": "à¨¸à¨¿à¨¸à¨Ÿà¨® à¨­à¨¾à¨¸à¨¼à¨¾ à¨¦à¨¾ à¨ªà¨¤à¨¾ à¨²à¨—à¨¾à¨‰à¨‚à¨¦à©‡ à¨¸à¨®à©‡à¨‚ à¨¤à¨°à©à©±à¨Ÿà©€: {}",
        "file_not_found": "à¨¤à¨°à©à©±à¨Ÿà©€: à¨«à¨¾à¨ˆà¨² à¨¨à¨¹à©€à¨‚ à¨®à¨¿à¨²à©€: {}",
        "json_decode_error": "JSON à¨¡à©€à¨•à©‹à¨¡ à¨¤à¨°à©à©±à¨Ÿà©€: {}",
        "start_processing": "ðŸš€ à¨ªà©à¨°à¨•à¨¿à¨°à¨¿à¨† à¨¸à¨¼à©à¨°à©‚ à¨¹à©‹ à¨°à¨¹à©€ à¨¹à©ˆ: {} à¨²à©‹à¨¡ à¨¹à©‹ à¨°à¨¿à¨¹à¨¾ à¨¹à©ˆ...",
        "extracted_entries": "{0} à¨à¨‚à¨Ÿà¨°à©€à¨†à¨‚ à¨¨à¨¿à¨•à¨¾à¨²à©€à¨†à¨‚ à¨—à¨ˆà¨†à¨‚, à¨œà¨¿à¨¨à©à¨¹à¨¾à¨‚ à¨µà¨¿à©±à¨šà©‹à¨‚ {1} Gemini à¨‡à¨¤à¨¿à¨¹à¨¾à¨¸ à¨¹à©ˆà¥¤",
        "converting_markdown": "Markdown à¨µà¨¿à©±à¨š à¨¬à¨¦à¨² à¨°à¨¿à¨¹à¨¾ à¨¹à©ˆ...",
        "appended_to_file": "à¨šà©ˆà¨Ÿ à¨‡à¨¤à¨¿à¨¹à¨¾à¨¸ à¨«à¨¾à¨ˆà¨² à¨µà¨¿à©±à¨š à¨¸à¨¼à¨¾à¨®à¨² à¨•à©€à¨¤à¨¾ à¨—à¨¿à¨†: {}",
        "written_to_file": "à¨šà©ˆà¨Ÿ à¨‡à¨¤à¨¿à¨¹à¨¾à¨¸ à¨«à¨¾à¨ˆà¨² à¨µà¨¿à©±à¨š à¨²à¨¿à¨–à¨¿à¨† à¨—à¨¿à¨†: {}",
        "processing_complete": "âœ… à¨®à©à¨•à©°à¨®à¨²: à¨‡à¨¤à¨¿à¨¹à¨¾à¨¸ {0} à¨¤à©‹à¨‚ {1} à¨¤à©±à¨• à¨•à©à©±à¨² {2} à¨«à¨¾à¨ˆà¨²à¨¾à¨‚ à¨µà¨¿à©±à¨š à¨¸à©à¨°à©±à¨–à¨¿à¨…à¨¤ à¨•à©€à¨¤à¨¾ à¨—à¨¿à¨†à¥¤",
        "error_occurred": "à¨‡à©±à¨• à¨¤à¨°à©à©±à¨Ÿà©€ à¨†à¨ˆ: {}",
    },
    "pt": {
        "error_lang_detection": "Erro ao detectar o idioma do sistema: {}",
        "file_not_found": "Erro: Arquivo nÃ£o encontrado: {}",
        "json_decode_error": "Erro de decodificaÃ§Ã£o JSON: {}",
        "start_processing": "ðŸš€ Iniciando processamento: Carregando {}...",
        "extracted_entries": "ExtraÃ­das {0} entradas, das quais {1} sÃ£o histÃ³rico do Gemini.",
        "converting_markdown": "Convertendo para Markdown...",
        "appended_to_file": "HistÃ³ricos de chat adicionados ao arquivo: {}",
        "written_to_file": "HistÃ³ricos de chat escritos no arquivo: {}",
        "processing_complete": "âœ… ConcluÃ­do: HistÃ³rico salvo de {0} a {1} em um total de {2} arquivos.",
        "error_occurred": "Ocorreu um erro: {}",
    },
    "ru": {
        "error_lang_detection": "ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ð¸ ÑÐ·Ñ‹ÐºÐ° ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹: {}",
        "file_not_found": "ÐžÑˆÐ¸Ð±ÐºÐ°: Ð¤Ð°Ð¹Ð» Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½: {}",
        "json_decode_error": "ÐžÑˆÐ¸Ð±ÐºÐ° Ð´ÐµÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ JSON: {}",
        "start_processing": "ðŸš€ ÐÐ°Ñ‡Ð°Ð»Ð¾ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸: Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° {}...",
        "extracted_entries": "Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¾ {0} Ð·Ð°Ð¿Ð¸ÑÐµÐ¹, Ð¸Ð· ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ñ… {1} Ð¾Ñ‚Ð½Ð¾ÑÑÑ‚ÑÑ Ðº Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Gemini.",
        "converting_markdown": "ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð² Markdown...",
        "appended_to_file": "Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ Ñ‡Ð°Ñ‚Ð° Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð° Ð² Ñ„Ð°Ð¹Ð»: {}",
        "written_to_file": "Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ Ñ‡Ð°Ñ‚Ð° Ð·Ð°Ð¿Ð¸ÑÐ°Ð½Ð° Ð² Ñ„Ð°Ð¹Ð»: {}",
        "processing_complete": "âœ… Ð—Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾: Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð° Ñ {0} Ð¿Ð¾ {1} Ð² Ð¾Ð±Ñ‰ÐµÐ¹ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸ Ð² {2} Ñ„Ð°Ð¹Ð»Ð°Ñ….",
        "error_occurred": "ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ°: {}",
    },
    "sw": {
        "error_lang_detection": "Hitilafu wakati wa kugundua lugha ya mfumo: {}",
        "file_not_found": "Hitilafu: Faili haikupatikana: {}",
        "json_decode_error": "Hitilafu ya kutafsiri JSON: {}",
        "start_processing": "ðŸš€ Kuanzia usindikaji: Inapakia {}...",
        "extracted_entries": "Imechota rekodi {0}, ambapo {1} ni historia ya Gemini.",
        "converting_markdown": "Inabadilisha kuwa Markdown...",
        "appended_to_file": "Historia za mazungumzo zimeongezwa kwenye faili: {}",
        "written_to_file": "Historia za mazungumzo zimeandikwa kwenye faili: {}",
        "processing_complete": "âœ… Imekamilika: Historia imehifadhiwa kutoka {0} hadi {1} katika jumla ya faili {2}.",
        "error_occurred": "Hitilafu imetokea: {}",
    },
    "ta": {
        "error_lang_detection": "à®šà®¿à®¸à¯à®Ÿà®®à¯ à®®à¯Šà®´à®¿à®¯à¯ˆ à®•à®£à¯à®Ÿà®±à®¿à®¤à®²à®¿à®²à¯ à®ªà®¿à®´à¯ˆ: {}",
        "file_not_found": "à®ªà®¿à®´à¯ˆ: à®•à¯‹à®ªà¯à®ªà¯ à®•à®¾à®£à®ªà¯à®ªà®Ÿà®µà®¿à®²à¯à®²à¯ˆ: {}",
        "json_decode_error": "JSON à®•à¯à®±à®¿à®¯à®¾à®•à¯à®• à®ªà®¿à®´à¯ˆ: {}",
        "start_processing": "ðŸš€ à®šà¯†à®¯à®²à®¾à®•à¯à®•à®®à¯ à®¤à¯Šà®Ÿà®™à¯à®•à¯à®•à®¿à®±à®¤à¯: {} à®à®±à¯à®±à®ªà¯à®ªà®Ÿà¯à®•à®¿à®±à®¤à¯...",
        "extracted_entries": "à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ {0} à¸£à¸²à¸¢à¸à¸²à¸£ à¸‹à¸¶à¹ˆà¸‡à¸¡à¸µà¸›à¸£à¸°à¸§à¸±à¸•à¸´à¸‚à¸­à¸‡ Gemini à¸ˆà¸³à¸™à¸§à¸™ {1} à¸£à¸²à¸¢à¸à¸²à¸£",
        "converting_markdown": "à¸à¸³à¸¥à¸±à¸‡à¹à¸›à¸¥à¸‡à¹€à¸›à¹‡à¸™ Markdown...",
        "appended_to_file": "à¸›à¸£à¸°à¸§à¸±à¸•à¸´à¸à¸²à¸£à¹à¸Šà¸—à¸–à¸¹à¸à¹€à¸žà¸´à¹ˆà¸¡à¸¥à¸‡à¹ƒà¸™à¹„à¸Ÿà¸¥à¹Œ: {}",
        "written_to_file": "à¸›à¸£à¸°à¸§à¸±à¸•à¸´à¸à¸²à¸£à¹à¸Šà¸—à¸–à¸¹à¸à¹€à¸‚à¸µà¸¢à¸™à¸¥à¸‡à¹ƒà¸™à¹„à¸Ÿà¸¥à¹Œ: {}",
        "processing_complete": "âœ… à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸´à¹‰à¸™: à¸šà¸±à¸™à¸—à¸¶à¸à¸›à¸£à¸°à¸§à¸±à¸•à¸´à¸ˆà¸²à¸ {0} à¸–à¸¶à¸‡ {1} à¸¥à¸‡à¹ƒà¸™à¹„à¸Ÿà¸¥à¹Œà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” {2} à¹„à¸Ÿà¸¥à¹Œ",
        "error_occurred": "à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”: {}",
    },
    "te": {
        "error_lang_detection": "à°¸à°¿à°¸à±à°Ÿà°®à± à°­à°¾à°·à°¨à± à°—à±à°°à±à°¤à°¿à°‚à°šà°¡à°‚à°²à±‹ à°²à±‹à°ªà°‚: {}",
        "file_not_found": "à°²à±‹à°ªà°‚: à°«à±ˆà°²à± à°•à°¨à±à°—à±Šà°¨à°¬à°¡à°²à±‡à°¦à±: {}",
        "json_decode_error": "JSON à°¡à±€à°•à±‹à°¡à± à°²à±‹à°ªà°‚: {}",
        "start_processing": "ðŸš€ à°ªà±à°°à°¾à°¸à±†à°¸à°¿à°‚à°—à± à°ªà±à°°à°¾à°°à°‚à°­à°‚: {} à°²à±‹à°¡à± à°…à°µà±à°¤à±‹à°‚à°¦à°¿...",
        "extracted_entries": "{0} à°Žà°‚à°Ÿà±à°°à±€à°²à± à°¤à±€à°¸à±à°•à±‹à°¬à°¡à±à°¡à°¾à°¯à°¿, à°µà°¾à°Ÿà°¿à°²à±‹ {1} à°œà±†à°®à°¿à°¨à±€ à°šà°°à°¿à°¤à±à°°.",
        "converting_markdown": "Markdown à°•à± à°®à°¾à°°à±à°šà°¡à°‚...",
        "appended_to_file": "à°šà°¾à°Ÿà± à°šà°°à°¿à°¤à±à°° à°«à±ˆà°²à±â€Œà°•à± à°œà±‹à°¡à°¿à°‚à°šà°¬à°¡à°¿à°‚à°¦à°¿: {}",
        "written_to_file": "à°šà°¾à°Ÿà± à°šà°°à°¿à°¤à±à°° à°«à±ˆà°²à±â€Œà°•à± à°°à°¾à°¯à°¬à°¡à°¿à°‚à°¦à°¿: {}",
        "processing_complete": "âœ… à°ªà±‚à°°à±à°¤à°¯à°¿à°‚à°¦à°¿: à°šà°°à°¿à°¤à±à°° {0} à°¨à±à°‚à°¡à°¿ {1} à°µà°°à°•à± à°®à±Šà°¤à±à°¤à°‚ {2} à°«à±ˆà°³à±à°²à°²à±‹ à°¸à±‡à°µà± à°šà±‡à°¯à°¬à°¡à°¿à°‚à°¦à°¿.",
        "error_occurred": "à°²à±‹à°ªà°‚ à°¸à°‚à°­à°µà°¿à°‚à°šà°¿à°‚à°¦à°¿: {}",
    },
    "th": {
        "error_lang_detection": "à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”à¸‚à¸“à¸°à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¸ à¸²à¸©à¸²à¸£à¸°à¸šà¸š: {}",
        "file_not_found": "à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”: à¹„à¸¡à¹ˆà¸žà¸šà¹„à¸Ÿà¸¥à¹Œ: {}",
        "json_decode_error": "à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¸–à¸­à¸”à¸£à¸«à¸±à¸ª JSON: {}",
        "start_processing": "ðŸš€ à¹€à¸£à¸´à¹ˆà¸¡à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥: à¸à¸³à¸¥à¸±à¸‡à¹‚à¸«à¸¥à¸” {}...",
        "extracted_entries": "à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ {0} à¸£à¸²à¸¢à¸à¸²à¸£ à¸‹à¸¶à¹ˆà¸‡à¸¡à¸µà¸›à¸£à¸°à¸§à¸±à¸•à¸´à¸‚à¸­à¸‡ Gemini à¸ˆà¸³à¸™à¸§à¸™ {1} à¸£à¸²à¸¢à¸à¸²à¸£",
        "converting_markdown": "à¸à¸³à¸¥à¸±à¸‡à¹à¸›à¸¥à¸‡à¹€à¸›à¹‡à¸™ Markdown...",
        "appended_to_file": "à¸›à¸£à¸°à¸§à¸±à¸•à¸´à¸à¸²à¸£à¹à¸Šà¸—à¸–à¸¹à¸à¹€à¸žà¸´à¹ˆà¸¡à¸¥à¸‡à¹ƒà¸™à¹„à¸Ÿà¸¥à¹Œ: {}",
        "written_to_file": "à¸›à¸£à¸°à¸§à¸±à¸•à¸´à¸à¸²à¸£à¹à¸Šà¸—à¸–à¸¹à¸à¹€à¸‚à¸µà¸¢à¸™à¸¥à¸‡à¹ƒà¸™à¹„à¸Ÿà¸¥à¹Œ: {}",
        "processing_complete": "âœ… à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸´à¹‰à¸™: à¸šà¸±à¸™à¸—à¸¶à¸à¸›à¸£à¸°à¸§à¸±à¸•à¸´à¸ˆà¸²à¸ {0} à¸–à¸¶à¸‡ {1} à¸¥à¸‡à¹ƒà¸™à¹„à¸Ÿà¸¥à¹Œà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” {2} à¹„à¸Ÿà¸¥à¹Œ",
        "error_occurred": "à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”: {}",
    },
    "tr": {
        "error_lang_detection": "Sistem dili algÄ±lanÄ±rken hata oluÅŸtu: {}",
        "file_not_found": "Hata: Dosya bulunamadÄ±: {}",
        "json_decode_error": "JSON kod Ã§Ã¶zme hatasÄ±: {}",
        "start_processing": "ðŸš€ Ä°ÅŸleme baÅŸlÄ±yor: {} yÃ¼kleniyor...",
        "extracted_entries": "{0} giriÅŸ Ã§Ä±karÄ±ldÄ±, bunlarÄ±n {1} tanesi Gemini geÃ§miÅŸi.",
        "converting_markdown": "Markdown'a dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor...",
        "appended_to_file": "Sohbet geÃ§miÅŸi dosyaya eklendi: {}",
        "written_to_file": "Sohbet geÃ§miÅŸi dosyaya yazÄ±ldÄ±: {}",
        "processing_complete": "âœ… TamamlandÄ±: {0} ile {1} arasÄ±ndaki geÃ§miÅŸ toplam {2} dosyaya kaydedildi.",
        "error_occurred": "Bir hata oluÅŸtu: {}",
    },
    "uk": {
        "error_lang_detection": "ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ñ–Ð´ Ñ‡Ð°Ñ Ð²Ð¸Ð·Ð½Ð°Ñ‡ÐµÐ½Ð½Ñ Ð¼Ð¾Ð²Ð¸ ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸: {}",
        "file_not_found": "ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ°: Ð¤Ð°Ð¹Ð» Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾: {}",
        "json_decode_error": "ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð´ÐµÐºÐ¾Ð´ÑƒÐ²Ð°Ð½Ð½Ñ JSON: {}",
        "start_processing": "ðŸš€ ÐŸÐ¾Ñ‡Ð°Ñ‚Ð¾Ðº Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸: Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ {}...",
        "extracted_entries": "Ð’Ð¸Ð»ÑƒÑ‡ÐµÐ½Ð¾ {0} Ð·Ð°Ð¿Ð¸ÑÑ–Ð², Ð· ÑÐºÐ¸Ñ… {1} ÑÑ‚Ð¾ÑÑƒÑŽÑ‚ÑŒÑÑ Ñ–ÑÑ‚Ð¾Ñ€Ñ–Ñ— Gemini.",
        "converting_markdown": "ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ñ–Ñ Ð² Markdown...",
        "appended_to_file": "Ð†ÑÑ‚Ð¾Ñ€Ñ–Ñ Ñ‡Ð°Ñ‚Ñƒ Ð´Ð¾Ð´Ð°Ð½Ð° Ð´Ð¾ Ñ„Ð°Ð¹Ð»Ñƒ: {}",
        "written_to_file": "Ð†ÑÑ‚Ð¾Ñ€Ñ–Ñ Ñ‡Ð°Ñ‚Ñƒ Ð·Ð°Ð¿Ð¸ÑÐ°Ð½Ð° Ñƒ Ñ„Ð°Ð¹Ð»: {}",
        "processing_complete": "âœ… Ð—Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾: Ð†ÑÑ‚Ð¾Ñ€Ñ–Ñ Ð· {0} Ð¿Ð¾ {1} Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð° ÑƒÑÑŒÐ¾Ð³Ð¾ Ð² {2} Ñ„Ð°Ð¹Ð»Ð°Ñ….",
        "error_occurred": "Ð¡Ñ‚Ð°Ð»Ð°ÑÑ Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ°: {}",
    },
    "ur": {
        "error_lang_detection": "Ø³Ø³Ù¹Ù… Ø²Ø¨Ø§Ù† Ú©Ø§ Ù¾ØªÛ Ù„Ú¯Ø§Ù†Û’ Ù…ÛŒÚº Ø®Ø±Ø§Ø¨ÛŒ: {}",
        "file_not_found": "Ø®Ø±Ø§Ø¨ÛŒ: ÙØ§Ø¦Ù„ Ù†ÛÛŒÚº Ù…Ù„ÛŒ: {}",
        "json_decode_error": "JSON ÚˆÛŒ Ú©ÙˆÚˆÙ†Ú¯ Ú©ÛŒ Ø®Ø±Ø§Ø¨ÛŒ: {}",
        "start_processing": "ðŸš€ Ù¾Ø±Ø§Ø³ÛŒØ³Ù†Ú¯ Ø´Ø±ÙˆØ¹ ÛÙˆ Ø±ÛÛŒ ÛÛ’: {} Ù„ÙˆÚˆ ÛÙˆ Ø±ÛØ§ ÛÛ’...",
        "extracted_entries": "{0} Ø§Ù†Ø¯Ø±Ø§Ø¬Ø§Øª Ù†Ú©Ø§Ù„Û’ Ú¯Ø¦Û’ØŒ Ø¬Ù† Ù…ÛŒÚº Ø³Û’ {1} Gemini Ú©ÛŒ ØªØ§Ø±ÛŒØ® ÛÛ’Û”",
        "converting_markdown": "Markdown Ù…ÛŒÚº ØªØ¨Ø¯ÛŒÙ„ Ú©ÛŒØ§ Ø¬Ø§ Ø±ÛØ§ ÛÛ’...",
        "appended_to_file": "Ú†ÛŒÙ¹ Ú©ÛŒ ØªØ§Ø±ÛŒØ® ÙØ§Ø¦Ù„ Ù…ÛŒÚº Ø´Ø§Ù…Ù„ Ú©Ø± Ø¯ÛŒ Ú¯Ø¦ÛŒ ÛÛ’: {}",
        "written_to_file": "Ú†ÛŒÙ¹ Ú©ÛŒ ØªØ§Ø±ÛŒØ® ÙØ§Ø¦Ù„ Ù…ÛŒÚº Ù„Ú©Ú¾ Ø¯ÛŒ Ú¯Ø¦ÛŒ ÛÛ’: {}",
        "processing_complete": "âœ… Ù…Ú©Ù…Ù„ ÛÙˆ Ú¯ÛŒØ§: ØªØ§Ø±ÛŒØ® {0} Ø³Û’ {1} ØªÚ© Ú©Ù„ {2} ÙØ§Ø¦Ù„ÙˆÚº Ù…ÛŒÚº Ù…Ø­ÙÙˆØ¸ Ú©Ø± Ø¯ÛŒ Ú¯Ø¦ÛŒ ÛÛ’Û”",
        "error_occurred": "Ø§ÛŒÚ© Ø®Ø±Ø§Ø¨ÛŒ Ù¾ÛŒØ´ Ø¢Ø¦ÛŒ: {}",
    },
    "vi": {
        "error_lang_detection": "Lá»—i khi phÃ¡t hiá»‡n ngÃ´n ngá»¯ há»‡ thá»‘ng: {}",
        "file_not_found": "Lá»—i: KhÃ´ng tÃ¬m tháº¥y tá»‡p: {}",
        "json_decode_error": "Lá»—i giáº£i mÃ£ JSON: {}",
        "start_processing": "ðŸš€ Báº¯t Ä‘áº§u xá»­ lÃ½: Äang táº£i {}...",
        "extracted_entries": "ÄÃ£ trÃ­ch xuáº¥t {0} má»¥c, trong Ä‘Ã³ cÃ³ {1} lÃ  lá»‹ch sá»­ Gemini.",
        "converting_markdown": "Äang chuyá»ƒn Ä‘á»•i sang Markdown...",
        "appended_to_file": "Lá»‹ch sá»­ trÃ² chuyá»‡n Ä‘Ã£ Ä‘Æ°á»£c thÃªm vÃ o tá»‡p: {}",
        "written_to_file": "Lá»‹ch sá»­ trÃ² chuyá»‡n Ä‘Ã£ Ä‘Æ°á»£c ghi vÃ o tá»‡p: {}",
        "processing_complete": "âœ… HoÃ n thÃ nh: ÄÃ£ lÆ°u lá»‹ch sá»­ tá»« {0} Ä‘áº¿n {1} vÃ o tá»•ng cá»™ng {2} tá»‡p.",
        "error_occurred": "ÄÃ£ xáº£y ra lá»—i: {}",
    },
    "zh_CN": {
        "error_lang_detection": "æ£€æµ‹ç³»ç»Ÿè¯­è¨€æ—¶å‡ºé”™ï¼š{}",
        "file_not_found": "é”™è¯¯ï¼šæœªæ‰¾åˆ°æ–‡ä»¶ï¼š{}",
        "json_decode_error": "JSON è§£ç é”™è¯¯ï¼š{}",
        "start_processing": "ðŸš€ å¼€å§‹å¤„ç†ï¼šæ­£åœ¨åŠ è½½ {}...",
        "extracted_entries": "æå–äº† {0} æ¡æ¡ç›®ï¼Œå…¶ä¸­ {1} æ¡æ˜¯ Gemini åŽ†å²è®°å½•ã€‚",
        "converting_markdown": "æ­£åœ¨è½¬æ¢ä¸º Markdown...",
        "appended_to_file": "èŠå¤©åŽ†å²å·²è¿½åŠ åˆ°æ–‡ä»¶ï¼š{}",
        "written_to_file": "èŠå¤©åŽ†å²å·²å†™å…¥æ–‡ä»¶ï¼š{}",
        "processing_complete": "âœ… å®Œæˆï¼šå·²å°† {0} åˆ° {1} ä¹‹é—´çš„åŽ†å²è®°å½•ä¿å­˜åˆ°å…±è®¡ {2} ä¸ªæ–‡ä»¶ä¸­ã€‚",
        "error_occurred": "å‘ç”Ÿé”™è¯¯ï¼š{}",
    },
    "zh_TW": {
        "error_lang_detection": "æª¢æ¸¬ç³»çµ±èªžè¨€æ™‚å‡ºéŒ¯ï¼š{}",
        "file_not_found": "éŒ¯èª¤ï¼šæœªæ‰¾åˆ°æ–‡ä»¶ï¼š{}",
        "json_decode_error": "JSON è§£ç¢¼éŒ¯èª¤ï¼š{}",
        "start_processing": "ðŸš€ é–‹å§‹è™•ç†ï¼šæ­£åœ¨åŠ è¼‰ {}...",
        "extracted_entries": "æå–äº† {0} æ¢æ¢ç›®ï¼Œå…¶ä¸­ {1} æ¢æ˜¯ Gemini æ­·å²è¨˜éŒ„ã€‚",
        "converting_markdown": "æ­£åœ¨è½‰æ›ç‚º Markdown...",
        "appended_to_file": "èŠå¤©æ­·å²å·²è¿½åŠ åˆ°æ–‡ä»¶ï¼š{}",
        "written_to_file": "èŠå¤©æ­·å²å·²å¯«å…¥æ–‡ä»¶ï¼š{}",
        "processing_complete": "âœ… å®Œæˆï¼šå·²å°‡ {0} åˆ° {1} ä¹‹é–“çš„æ­·å²è¨˜éŒ„ä¿å­˜åˆ°å…±è¨ˆ {2} å€‹æ–‡ä»¶ä¸­ã€‚",
        "error_occurred": "ç™¼ç”ŸéŒ¯èª¤ï¼š{}",
    },
}


def get_system_language() -> str:
    """detect OS language setting"""
    try:
        lang_tuple = locale.getlocale()
        if lang_tuple[0]:
            lang_name = lang_tuple[0].split("_")[0]
            lang_code = LANG_MAP.get(lang_name, lang_name[:2].lower())
        else:
            lang_code = None

        if lang_code is None:
            return "en"

        if lang_code == "zh_CN" or lang_code == "zh-Hans" or lang_name == "Chinese_China":
            return "zh_CN"
        elif lang_code == "zh_TW" or lang_code == "zh-Hant" or lang_name == "Chinese_Taiwan":
            return "zh_TW"

        lang_code = lang_code.split("_")[0].split("-")[0].lower()
        if lang_code in TRANSLATIONS:
            return lang_code
        return "en"

    except Exception as e:
        error_msg = TRANSLATIONS.get("en", {}).get("error_lang_detection", "Error: {}")
        print(error_msg.format(e))
        return "en"


def t(key: str, *args: Any) -> str:
    """Translation function"""
    lang = get_system_language()

    msg_map: dict[str, str] = TRANSLATIONS.get(lang, TRANSLATIONS["en"])
    msg: str = msg_map.get(key, TRANSLATIONS["en"].get(key, key))

    if args:
        try:
            return msg.format(*args)
        except IndexError:
            # Safety measure in case the number of placeholders and variables do not match
            return msg
    return msg


def load_json(filepath: str) -> list[dict[str, Any]]:
    """Load a JSON file"""
    if not os.path.exists(filepath):
        print(t("file_not_found", filepath))
        return []

    with open(filepath, encoding="utf-8") as f:
        try:
            return json.load(f)
        except json.JSONDecodeError as e:
            print(t("json_decode_error", e))
            return []


def decode_unicode_escapes(s: str) -> str:
    """Decode Unicode escape sequences"""

    def repl(match):
        return chr(int(match.group(1), 16))

    return re.sub(r"\\u([0-9a-fA-F]{4})", repl, s)


def html_to_markdown(html_str: str) -> str:
    """
    Simple HTML -> Markdown/Text conversion
    Remove HTML tags and format into readable text
    """
    if not html_str:
        return ""

    text = decode_unicode_escapes(html_str)
    text = html_module.unescape(text)

    # Replace major tags (h1-h6, li, p, div, br, b, strong) with Markdown-like symbols and line breaks
    # Headings (h1-h6) -> **Heading** + line break
    text = re.sub(r"<h[1-6][^>]*>(.*?)</h[1-6]>", r"\n**\1**\n", text, flags=re.IGNORECASE)

    # List items (li) -> - + line break
    text = re.sub(r"<li[^>]*>", r"\n- ", text, flags=re.IGNORECASE)

    # Paragraphs (p), line breaks (div), line breaks (br) -> line breaks
    text = re.sub(r"</p>", r"\n\n", text, flags=re.IGNORECASE)
    text = re.sub(r"</div>", r"\n", text, flags=re.IGNORECASE)
    text = re.sub(r"<br\s*/?>", r"\n", text, flags=re.IGNORECASE)

    # Bold (b, strong) -> **text**
    text = re.sub(r"<(b|strong)[^>]*>(.*?)</\1>", r"**\2**", text, flags=re.IGNORECASE)

    # Remove all other HTML tags (keep the content)
    text = re.sub(r"<[^>]+>", "", text)

    # Organize consecutive blank lines (reduce 3 or more line breaks to 2)
    text = re.sub(r"\n{3,}", "\n\n", text)

    return text.strip()


def extract_text_content(entry: dict[str, Any], last_entry_time_loaded: datetime) -> tuple[datetime, str]:
    """Extract Markdown-formatted text content from an entry"""

    time_str = entry.get("time", "")
    dt: datetime = datetime.min.replace(tzinfo=timezone.utc)  # Default value
    try:
        dt = datetime.fromisoformat(time_str.replace("Z", "+00:00"))
        if dt <= last_entry_time_loaded:
            return dt, ""  # Skip already processed entries
        formatted_date = dt.strftime("%Y/%m/%d %H:%M:%S")
    except ValueError:
        formatted_date = time_str

    md_output = f"## {formatted_date}\n\n"

    # 1. Action
    title = entry.get("title", "")
    if title:
        md_output += f"**Action**: {title}\n\n"

    # 2. User Prompt (subtitles)
    subtitles = entry.get("subtitles", [])
    if subtitles:
        for item in subtitles:
            name = item.get("name", "User")
            value = item.get("value", "")
            if value:
                # Format in Markdown
                md_output += f"### {name}\n"
                formatted_value = value.replace(chr(10), "  \n")  # Replace line breaks for Markdown
                md_output += f"{formatted_value}\n\n"

    # 3. Gemini Response (safeHtmlItem)
    safeHtmlItem = entry.get("safeHtmlItem", [])
    if safeHtmlItem:
        response_text = ""
        for item in safeHtmlItem:
            html = item.get("html", "")
            if html:
                # Convert HTML to text/Markdown and concatenate
                converted_text = html_to_markdown(html)
                response_text += converted_text + "\n\n"

        # Output header only if there is content
        if response_text.strip():
            md_output += "### Gemini (Response)\n"
            md_output += f"{response_text}\n"

    md_output += "---\n\n"  # Separator
    return dt, md_output


def main() -> None:
    parser = argparse.ArgumentParser(description="Convert Google Takeout JSON to Markdown for NotebookLM")
    parser.add_argument(
        "--input_file", metavar="FILE", type=str, default="MyActivity.json", help="Path to input JSON file"
    )
    parser.add_argument(
        "--output_file",
        metavar="FILE",
        type=str,
        default="Gemini_History.md",
        help="Path to output Markdown file",
    )
    parser.add_argument("--limit", type=int, default=1500000, help="Split file size limit in bytes")

    args = parser.parse_args()
    input_json_filename: str = args.input_file
    output_md_filename: str = args.output_file
    md_file_size_limit: int = args.limit

    try:
        print(t("start_processing", input_json_filename))

        data = load_json(input_json_filename)
        if not data:
            return

        # Filter only "Gemini" related activities
        gemini_entries: list[dict[str, Any]] = [
            entry for entry in data if "Gemini" in entry.get("header", "")
        ]

        print(t("extracted_entries", len(data), len(gemini_entries)))
        print(t("converting_markdown"))

        gemini_entries.reverse()

        last_entry_time_loaded: datetime = datetime.min.replace(tzinfo=timezone.utc)
        last_entry_time_processed: datetime = datetime.min.replace(tzinfo=timezone.utc)
        if os.path.exists(LAST_ENTRY_TIME_FILE):
            with open(LAST_ENTRY_TIME_FILE, encoding="utf-8") as f:
                time_str = f.read().strip()
                with contextlib.suppress(ValueError):
                    last_entry_time_loaded = datetime.fromisoformat(time_str)

        base_name, ext = os.path.splitext(output_md_filename)

        def get_output_filename(idx: int) -> str:
            return f"{base_name}-{idx:02d}{ext}"

        file_index = 1
        is_append_mode = False
        while os.path.exists(get_output_filename(file_index)):
            is_append_mode = True
            file_index += 1
            output_filename = get_output_filename(file_index)
        if file_index > 1:
            file_index -= 1  # Use the last existing file for appending
        output_filename = get_output_filename(file_index)
        current_file_size = 0
        if is_append_mode:
            current_file_size = os.path.getsize(output_filename)

        header = "# Gemini Chat History Archive\n\n"
        header += f"Generated at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"

        def write_file(output_filename: str, header: str, texts: list[str], is_append_mode: bool) -> None:
            mode = "a" if is_append_mode else "w"
            with open(output_filename, mode, encoding="utf-8") as f:
                f.write(header)
                for text in texts:
                    f.write(text)

        texts = []
        current_file_size += len(header.encode("utf-8"))

        for _, entry in enumerate(gemini_entries):
            dt, text = extract_text_content(entry, last_entry_time_loaded)
            if text == "":
                continue
            last_entry_time_processed = dt
            text_size = len(text.encode("utf-8"))

            if current_file_size + text_size > md_file_size_limit:
                if texts:
                    write_file(output_filename, header, texts, is_append_mode)
                    print(
                        t("appended_to_file", output_filename)
                        if is_append_mode
                        else t("written_to_file", output_filename)
                    )
                file_index += 1
                output_filename = get_output_filename(file_index)
                is_append_mode = False
                texts = []
                current_file_size = len(header.encode("utf-8"))

            texts.append(text)
            current_file_size += text_size

        if texts:
            write_file(output_filename, header, texts, is_append_mode)
            print(
                t("appended_to_file", output_filename)
                if is_append_mode
                else t("written_to_file", output_filename)
            )

        if last_entry_time_loaded < last_entry_time_processed:
            with open(LAST_ENTRY_TIME_FILE, "w", encoding="utf-8") as f:
                f.write(last_entry_time_processed.isoformat())

        print(t("processing_complete", last_entry_time_loaded, last_entry_time_processed, file_index))
    except Exception as e:
        print(t("error_occurred", e))


if __name__ == "__main__":
    main()
